{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from pyparsing import anyOpenTag, anyCloseTag\n",
    "from xml.sax.saxutils import unescape as unescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "with open(\"data/train.dat\", \"r\") as tr:\n",
    "    docs2 = tr.readlines()\n",
    "with open(\"data/test.dat\", \"r\") as te:\n",
    "    docs3 = te.readlines()\n",
    "\n",
    "#print len(docs1)\n",
    "cls = []\n",
    "reviewsdocs2 = []\n",
    "reviews1 = []\n",
    "for x in docs2:\n",
    "    cls.append(x[0:2])\n",
    "    reviewsdocs2.append(x[3:])\n",
    "reviews = reviewsdocs2 + docs3\n",
    "#print cls[0]\n",
    "#print reviews[0]\n",
    "#print len(docs2)\n",
    "#print len(docs1)\n",
    "#print len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33580\n"
     ]
    }
   ],
   "source": [
    "#removing html tag\n",
    "unescape_xml_entities = lambda k: unescape(k, {\"&apos;\": \"'\", \"&quot;\": '\"', \"&nbsp;\":\" \"})\n",
    "\n",
    "stripper = (anyOpenTag | anyCloseTag).suppress()\n",
    "for i in range(0, len(reviews)):\n",
    "    #print (\"in loop\")\n",
    "    reviews1.append(unescape_xml_entities(stripper.transformString(reviews[i])))\n",
    "#print reviews1[0]\n",
    "print len(reviews1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0fe85363d3af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#reviews1 = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mreviews1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^a-zA-Z0-9]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreviews1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#print reviews1[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#print reviews1[0]\n",
    "r\"\"\"removing special characters from all the reviews\"\"\"\n",
    "reviewwords = []\n",
    "reviewwords1 = []\n",
    "#reviews1 = []\n",
    "for i in range(0, 50000):\n",
    "    reviews1[i] = re.sub('[^a-zA-Z0-9]', ' ', reviews1[i])\n",
    "    \n",
    "#print reviews1[0]\n",
    "#print (reviewwords[0])   \n",
    "r\"\"\"splitting the lines into words and changing to lowercase letters\"\"\"\n",
    "for i in range(0, 50000):\n",
    "    reviewwords.append(reviews1[i].split())\n",
    "    for j in range(0, len(reviewwords[i])):\n",
    "        reviewwords[i][j] = reviewwords[i][j].lower()\n",
    "#print reviewwords[0]\n",
    "r\"\"\"removing words which have less than specified length\"\"\"\n",
    "def removeLesLenWords(docs, len_min):\n",
    "    #doc_new = []\n",
    "    docs_new = []\n",
    "    for d in docs:\n",
    "        doc_new = []\n",
    "        for word in d:\n",
    "            if len(word) >= len_min :\n",
    "                doc_new.append(word)\n",
    "        docs_new.append(doc_new)\n",
    "    return docs_new\n",
    "        \n",
    "reviewwords1 = removeLesLenWords(reviewwords, 4)\n",
    "\n",
    "\n",
    "#for i in range(0, 25000):\n",
    "#    for j in range(0, len(reviewwords[i])):\n",
    "#        reviewwords[i][j] = re.sub('[^a-zA-Z0-9]', ' ', reviewwords[i][j])\n",
    "#print (reviewwords[0])    \n",
    "\n",
    "    \n",
    "#print (\"iam done\")\n",
    "#print len(reviewwords1)\n",
    "#print (reviewwords1[0])\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "def csr_idf(mat, copy=False, **kargs):\n",
    "    r\"\"\" Scale a CSR matrix by idf. \n",
    "    Returns scaling factors as dict. If copy is True, \n",
    "    returns scaled matrix and scaling factors.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # document frequency\n",
    "    df = defaultdict(int)\n",
    "    for i in ind:\n",
    "        df[i] += 1\n",
    "    # inverse document frequency\n",
    "    for k,v in df.items():\n",
    "        df[k] = np.log(nrows / float(v))  ## df turns to idf - reusing memory\n",
    "    # scale by idf\n",
    "    for i in range(0, nnz):\n",
    "        val[i] *= df[ind[i]]\n",
    "        \n",
    "    return df if copy is False else mat\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )\n",
    "        \n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nrows 50000, ncols 99495, nnz 5180780]\n",
      "(50000, 99495)\n"
     ]
    }
   ],
   "source": [
    "csrmat1 = build_matrix(reviewwords1)\n",
    "csr_info(csrmat1)\n",
    "#print csrmat1.shape\n",
    "#csrmat1_v3 = csrmat1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done here\n"
     ]
    }
   ],
   "source": [
    "csrmat1_2 = csr_idf(csrmat1, copy=True)\n",
    "csrmat2 = csr_l2normalize(csrmat1_2, copy=True)\n",
    "#print (\"done here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done here\n"
     ]
    }
   ],
   "source": [
    "train1 = csrmat2[:25000, :]\n",
    "test1 = csrmat2[25000:, :] \n",
    "#test3 = csrmat2[46000:50000, :]\n",
    "print (\"done here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 99495)\n",
      "(25000, 99495)\n",
      "(4000, 99495)\n"
     ]
    }
   ],
   "source": [
    "print train1.shape\n",
    "print test1.shape\n",
    "#print test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finding cosine similarity\n",
    "#cossim = test3.dot(train1.T)\n",
    "cossim = test1.dot(train1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.0070030792352\n",
      "  (0, 7)\t0.0252774997891\n",
      "  (0, 5)\t0.0281380174512\n",
      "  (0, 4)\t0.027740789193\n",
      "  (0, 3)\t0.0162115308632\n",
      "  (0, 8)\t0.00627028666443\n",
      "  (0, 6)\t0.0139364533935\n",
      "  (0, 2)\t0.00990766460993\n",
      "  (0, 1)\t0.0164253886776\n",
      "  (0, 0)\t0.0168124438028\n",
      "4000\n",
      "[[ 0.01817613  0.01436508  0.01462237 ...,  0.00681425  0.02278709\n",
      "   0.00537141]\n",
      " [ 0.04888674  0.02116101  0.00580216 ...,  0.0035885   0.05161022\n",
      "   0.0101956 ]\n",
      " [ 0.02954106  0.02971903  0.0240926  ...,  0.02913416  0.03744943\n",
      "   0.02469659]\n",
      " ..., \n",
      " [ 0.0156422   0.02003334  0.00401671 ...,  0.01497766  0.01014766\n",
      "   0.03053537]\n",
      " [ 0.00994547  0.00720864  0.0016454  ...,  0.00352074  0.02922099\n",
      "   0.0091293 ]\n",
      " [ 0.03530439  0.0074691   0.00271132 ...,  0.00551852  0.02049963\n",
      "   0.00442865]]\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "#print cossim.shape[0]\n",
    "simlist = []\n",
    "simlist = cossim.toarray()\n",
    "#print cossim.toarray()\n",
    "#print (\"in the middle\")\n",
    "#print simlist[0]\n",
    "#print len(simlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print simlist[900]\n",
    "xlen = len(simlist)\n",
    "k = 150\n",
    "#x = simlist[900]\n",
    "#y = np.argsort(x)\n",
    "#z= x[y]\n",
    "#z = []\n",
    "#print z\n",
    "#print z[23000]\n",
    "#print x[23000]\n",
    "test_cls = []\n",
    "\n",
    "for i in range (0, xlen):\n",
    "    x = simlist[i]\n",
    "    y = np.argsort(simlist[i])\n",
    "    #z.append(x[y])\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    ylen = len(y)\n",
    "    z = y[ylen-k:]\n",
    "    zlen = len(z)\n",
    "    for j in range(0, zlen):\n",
    "        if cls[z[j]]== '+1' :\n",
    "            pos_count = pos_count+1\n",
    "        else:\n",
    "            neg_count = neg_count+1\n",
    "    if pos_count > neg_count:\n",
    "        test_cls.append('+1')\n",
    "    else:\n",
    "        test_cls.append('-1')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = open(\"data/result.dat\", \"w\")\n",
    "for i in range(0, len(test_cls)):\n",
    "    test.write(test_cls[i])\n",
    "    test.write('\\n')\n",
    "test.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
